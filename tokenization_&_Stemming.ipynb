{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOo/2JyV08tRvk7DYVqdeHE",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Varshi45/FML/blob/main/tokenization_%26_Stemming.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C_mGaQRz8TfO",
        "outputId": "7da62b29-8c4e-4f34-aa34-1dc3178a142f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('punkt')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Word tokenization and sentence tokenization**"
      ],
      "metadata": {
        "id": "ktkw2eYh_M2a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "from nltk.tokenize import sent_tokenize"
      ],
      "metadata": {
        "id": "PvCxue8P83_J"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"\"\"By the early 1960s an experimental \"learning machine\" with punched tape memory, called CyberTron, had been developed by Raytheon Company to analyze sonar signals, electrocardiograms, and speech patterns using rudimentary reinforcement learning. It was repetitively \"trained\" by a human operator/teacher to recognize patterns and equipped with a \"goof\" button to cause it to re-evaluate incorrect decisions.[16] A representative book on research into machine learning during the 1960s was Nilsson's book on Learning Machines, dealing mostly with machine learning for pattern classification.[17] Interest related to pattern recognition continued into the 1970s, as described by Duda and Hart in 1973.[18] In 1981 a report was given on using teaching strategies so that a neural network learns to recognize 40 characters (26 letters, 10 digits, and 4 special symbols) from a computer terminal.[19]\"\"\""
      ],
      "metadata": {
        "id": "U-JxgNst9Jbz"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokens = word_tokenize(text)\n",
        "print(\"Number of Tokens : \",len(tokens))\n",
        "print(tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3swXsvi9-MfW",
        "outputId": "03d3d88f-81e3-4a33-b244-8cce228d4cbe"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of Tokens :  164\n",
            "['By', 'the', 'early', '1960s', 'an', 'experimental', '``', 'learning', 'machine', \"''\", 'with', 'punched', 'tape', 'memory', ',', 'called', 'CyberTron', ',', 'had', 'been', 'developed', 'by', 'Raytheon', 'Company', 'to', 'analyze', 'sonar', 'signals', ',', 'electrocardiograms', ',', 'and', 'speech', 'patterns', 'using', 'rudimentary', 'reinforcement', 'learning', '.', 'It', 'was', 'repetitively', '``', 'trained', \"''\", 'by', 'a', 'human', 'operator/teacher', 'to', 'recognize', 'patterns', 'and', 'equipped', 'with', 'a', '``', 'goof', \"''\", 'button', 'to', 'cause', 'it', 'to', 're-evaluate', 'incorrect', 'decisions', '.', '[', '16', ']', 'A', 'representative', 'book', 'on', 'research', 'into', 'machine', 'learning', 'during', 'the', '1960s', 'was', 'Nilsson', \"'s\", 'book', 'on', 'Learning', 'Machines', ',', 'dealing', 'mostly', 'with', 'machine', 'learning', 'for', 'pattern', 'classification', '.', '[', '17', ']', 'Interest', 'related', 'to', 'pattern', 'recognition', 'continued', 'into', 'the', '1970s', ',', 'as', 'described', 'by', 'Duda', 'and', 'Hart', 'in', '1973', '.', '[', '18', ']', 'In', '1981', 'a', 'report', 'was', 'given', 'on', 'using', 'teaching', 'strategies', 'so', 'that', 'a', 'neural', 'network', 'learns', 'to', 'recognize', '40', 'characters', '(', '26', 'letters', ',', '10', 'digits', ',', 'and', '4', 'special', 'symbols', ')', 'from', 'a', 'computer', 'terminal', '.', '[', '19', ']']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentence = sent_tokenize(text)\n",
        "print(\"Number of sentences : \",len(sentence))\n",
        "print(sentence)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d30gMxA7-gNj",
        "outputId": "55e2bca7-fb5c-46b5-ae3d-91c0e82a90e6"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of sentences :  6\n",
            "['By the early 1960s an experimental \"learning machine\" with punched tape memory, called CyberTron, had been developed by Raytheon Company to analyze sonar signals, electrocardiograms, and speech patterns using rudimentary reinforcement learning.', 'It was repetitively \"trained\" by a human operator/teacher to recognize patterns and equipped with a \"goof\" button to cause it to re-evaluate incorrect decisions.', \"[16] A representative book on research into machine learning during the 1960s was Nilsson's book on Learning Machines, dealing mostly with machine learning for pattern classification.\", '[17] Interest related to pattern recognition continued into the 1970s, as described by Duda and Hart in 1973.', '[18] In 1981 a report was given on using teaching strategies so that a neural network learns to recognize 40 characters (26 letters, 10 digits, and 4 special symbols) from a computer terminal.', '[19]']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Stemmming**"
      ],
      "metadata": {
        "id": "3X9R-768_YEX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import PorterStemmer\n",
        "\n",
        "porter = PorterStemmer()"
      ],
      "metadata": {
        "id": "C2zQeNZE-zru"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def stemSentence(sentence):\n",
        "  tokens = word_tokenize(sentence)\n",
        "  print(tokens)\n",
        "  stem_sentence = []\n",
        "  for w in tokens :\n",
        "    stem_sentence.append(porter.stem(w))\n",
        "    stem_sentence.append(\" \")\n",
        "  return \"\".join(stem_sentence)\n",
        "\n",
        "\n",
        "x = stemSentence(text)\n",
        "print(\"After Stemming : \",x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ywmnmK6o_ifU",
        "outputId": "c28f843b-97b1-45e0-edec-111a874aff12"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['By', 'the', 'early', '1960s', 'an', 'experimental', '``', 'learning', 'machine', \"''\", 'with', 'punched', 'tape', 'memory', ',', 'called', 'CyberTron', ',', 'had', 'been', 'developed', 'by', 'Raytheon', 'Company', 'to', 'analyze', 'sonar', 'signals', ',', 'electrocardiograms', ',', 'and', 'speech', 'patterns', 'using', 'rudimentary', 'reinforcement', 'learning', '.', 'It', 'was', 'repetitively', '``', 'trained', \"''\", 'by', 'a', 'human', 'operator/teacher', 'to', 'recognize', 'patterns', 'and', 'equipped', 'with', 'a', '``', 'goof', \"''\", 'button', 'to', 'cause', 'it', 'to', 're-evaluate', 'incorrect', 'decisions', '.', '[', '16', ']', 'A', 'representative', 'book', 'on', 'research', 'into', 'machine', 'learning', 'during', 'the', '1960s', 'was', 'Nilsson', \"'s\", 'book', 'on', 'Learning', 'Machines', ',', 'dealing', 'mostly', 'with', 'machine', 'learning', 'for', 'pattern', 'classification', '.', '[', '17', ']', 'Interest', 'related', 'to', 'pattern', 'recognition', 'continued', 'into', 'the', '1970s', ',', 'as', 'described', 'by', 'Duda', 'and', 'Hart', 'in', '1973', '.', '[', '18', ']', 'In', '1981', 'a', 'report', 'was', 'given', 'on', 'using', 'teaching', 'strategies', 'so', 'that', 'a', 'neural', 'network', 'learns', 'to', 'recognize', '40', 'characters', '(', '26', 'letters', ',', '10', 'digits', ',', 'and', '4', 'special', 'symbols', ')', 'from', 'a', 'computer', 'terminal', '.', '[', '19', ']']\n",
            "After Stemming :  by the earli 1960 an experiment `` learn machin '' with punch tape memori , call cybertron , had been develop by raytheon compani to analyz sonar signal , electrocardiogram , and speech pattern use rudimentari reinforc learn . it wa repetit `` train '' by a human operator/teach to recogn pattern and equip with a `` goof '' button to caus it to re-evalu incorrect decis . [ 16 ] a repres book on research into machin learn dure the 1960 wa nilsson 's book on learn machin , deal mostli with machin learn for pattern classif . [ 17 ] interest relat to pattern recognit continu into the 1970 , as describ by duda and hart in 1973 . [ 18 ] in 1981 a report wa given on use teach strategi so that a neural network learn to recogn 40 charact ( 26 letter , 10 digit , and 4 special symbol ) from a comput termin . [ 19 ] \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "B7R61IpsELEg"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}